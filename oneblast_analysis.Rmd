---
title: "DoD Military Community and Family Policy Military OneSource eNewsletter"
author: "Paul Testa and Jake Bowers"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
    html_document:
        toc: TRUE
---

```{r init,echo=F}
## Easy way to look for and install missing packages and load them
if (!require("pacman")){ install.packages("pacman") }
pacman::p_load("knitr","openssl","mosaic","plyr","coin","ggplot")
## library(knitr)
opts_chunk$set(eval=T,echo=F,results="hide",message=F,warning=F,cache=T)

```

\tableofcontents

# Setup

- Download "wrkdat.csv" and "subscribersPlus.csv" onto local machine in the data subdirectory
- Load files and libaries

```{r setup}
wrkdat<-read.csv("data/wrkdat.csv",as.is=TRUE)
subscribers<-read.csv("data/subscribersPlus.csv",as.is=TRUE)

```

The outcome is whether or not a member of the experimental pool subscribed to the newsletter. We currently assume that all members of the experimental pool who have a 0 for subscribed did not subscribe under a different name and email address. We return to scrutinize the effect of this assumption later.

```{r dv}
# Use this as the primary DV
table(wrkdat$subscribed,exclude=c())
```

Because the experiment was randomized by batch, and because of trouble matching subscribers uniquely to the experimental pool, we analyze the data by a collapsed version of the 82 batch indicators that we call `batchday`. Nearly all batches were sent 2 per day and the subscriber data only has day of subscription, not hour or minute.

Do we have enough information to reject the claim that there are no differences between the treatments? We use the generalized Cochran-Mantel-Haensel test to address this question. We are using the coin library because it allows for easy assessment of this test without large sample assumptions.

```{r cmh}
library(coin)

wrkdat$batchday2F<-factor(wrkdat$batchday2)
wrkdat$treatmentF<-factor(wrkdat$treatment)
wrkdat$subscribedF<-factor(wrkdat$subscribed)

## Checking for missing data
##bigtab<-with(wrkdat,table(batchday2F,treatmentF,subscribed,exclude=c()))
bigtab<-with(wrkdat,table(treatmentF,subscribed,batchday2F))

cmh1approx<-cmh_test(subscribedF~treatmentF|batchday2F,data=wrkdat,distribution=approximate(B=1000))
cmh1<-cmh_test(subscribedF~treatmentF|batchday2F,data=wrkdat)
cmh2 <- mantelhaen.test(bigtab)

cmh1
```

There is a lot of evidence against the idea that all six emails had the same effect. 

# Estimate Difference of Proportions

Now we'll start to draw comparisons between specific treatments and groups of treatments. 

In the figure below we show the proportions subscribing in each treatment group with 95-percent confidence intervals. Treatments B and F appear to be the most successful at encouraging subscription to the newsletter.

```{r fig1}
# Wrapper function to grab proportions and CIs
prop_fn<-function(x){
    n<-length(x)
    success<-sum(x==1)
    proptest<-prop.test(success,n)
    return(c(proptest$estimate,proptest$conf.int))
}

# Split data by treatment
# Apply proportion function to each level of treatment
# Combine results into data frame for plotting with ggplot
table(wrkdat$treatment)
theprops<-as.data.frame(t(matrix(unlist(lapply(split(wrkdat$subscribed,f=wrkdat$treatment),prop_fn)),nrow=3))
       )
# Add names and Treatment indicator
colnames(theprops)<-c("pbar","ll","ul")
theprops$Treatment<-c("Opt-in; List",
                      "Active; List",
                      "Opt-in; Quiz",
                      "Active; Quiz",
                      "Opt-in",
                      "Active"
                      )
# Plot with ggplot2
## library(ggplot2)
dodge<-position_dodge(width = 0.9)
p.props<-ggplot(theprops,aes(Treatment,pbar,fill=Treatment))+
    geom_bar(stat = "identity", position = dodge)+
    geom_errorbar(aes(ymin=ll,ymax=ul),position = dodge,width=.25)+
    labs(list(y="Proportion Subscribing to Newsletter",
         title="Proportion Subscribing by Treatment Group"))+ theme(
  axis.text.x = element_blank(),axis.ticks.x = element_blank())
p.props
```


Next we provide a more formal assessment of the 15 pairwise comparisons by conducting a Tukey Honest Signficant Differences test on an ANOVA model weighted by the size of each batch, with family-wise confidence intervals that reflect the fact that we are making multiple comparisons.

```{r tukeyHSD}
wrkdat$sBatchAve<-ave(wrkdat$subscribed,wrkdat$batchday2F)
# Anova weighted by size of batch
a1<-aov(I(subscribed-sBatchAve)~treatmentF,wrkdat)
# Anova without adjusting for batch
a1_unweighted<-aov(subscribed~treatmentF,wrkdat)
# Adjusting for batch reductes size of confidence interval
apply(TukeyHSD(a1)$treatmentF[,2:3],1,diff)<apply(TukeyHSD(a1_unweighted)$treatmentF[,2:3],1,diff)
```

We see from the figure that `r sum(TukeyHSD(a1)$treatmentF[,4]<0.05)` out of the `r choose(6,2)` pairwise comparisons are statistically distinguishable from 0 (p<0.05). Specifically, the effects for Treatment F are significantly larger than any other treatment except Treatment B. The effect for Treatment B, although larger than the remaining Treatments (A,C,D and E) is only distinguishable from Treatment C.

```{r figTukey}
# Get estimates and intervals
tukey<-data.frame(TukeyHSD(a1)$treatmentF)
plot(TukeyHSD(a1))
tukey$Comparison<-factor(rownames(tukey),levels=rev(rownames(tukey)))

p.tukey<-ggplot(tukey,aes(y=Comparison,x=diff))+
    geom_vline(xintercept=0,linetype = 2,col="red")+
    geom_errorbarh(aes(xmin=lwr,xmax=upr),height=.25,col="grey")+
        geom_point()+
    labs(x="Difference in proportions",title="95% family-wise confidence level")
    

p.tukey
```

# Tests differences in the prespecified subgroups of treatments


This section makes the following comparisons:

- A,C,E versus B,D,F (a test of opt-in versus enhanced active).
- A,B,C,D versus E,F (a test of Block of 10 present versus absent)
- A,B versus C,D (a test of list versus quiz format)

To make life easier, we'll create indicators of these groupings, write a function to conduct generalized Cochran-Mantel-Haensel tests of these differences, accounting for batch^[We also need to fix some code in the mantelhaen.test to tell R to treat integers as floating point values]

```{r subgroup}
# A,C,E versus B,D,F (a test of opt-in versus enhanced active).
wrkdat$treat_bdf_01<-as.numeric(grepl("B|D|F",wrkdat$treatment))
wrkdat$treat_bdf<-factor(ifelse(grepl("B|D|F",wrkdat$treatment),"Enhanced Active","Opt-In"))
table(wrkdat$treat_bdf)
# A,B,C,D versus E,F (a test of Block of 10 present versus active)
wrkdat$treat_abcd_01<-as.numeric(grepl("A|B|C|D",wrkdat$treatment))
wrkdat$treat_abcd<-ifelse(grepl("A|B|C|D",wrkdat$treatment),"Present","Absent")
wrkdat$treat_abcd<-factor(wrkdat$treat_abcd,levels=c("Present","Absent"))

# A,B versus C,D (a test of list versus quiz format)
wrkdat$treat_ab_01<-as.numeric(grepl("A|B",wrkdat$treatment))
wrkdat$treat_ab_01[!grepl("A|B|C|D",wrkdat$treatment)]<-NA
wrkdat$treat_ab<-factor(ifelse(wrkdat$treat_ab_01==1,"List","Quiz"))

# Update mantel-haenszel test so it can calculate CIs for odds ratio

my.mantelhaen.test<-function (x, y = NULL, z = NULL, alternative = c("two.sided", 
                                                 "less", "greater"), correct = TRUE, exact = FALSE, conf.level = 0.95) 
{
    DNAME <- deparse(substitute(x))
    if (is.array(x)) {
        if (length(dim(x)) == 3L) {
            if (anyNA(x)) 
                stop("NAs are not allowed")
            if (any(dim(x) < 2L)) 
                stop("each dimension in table must be >= 2")
        }
        else stop("'x' must be a 3-dimensional array")
    }
    else {
        if (is.null(y)) 
            stop("if 'x' is not an array, 'y' must be given")
        if (is.null(z)) 
            stop("if 'x' is not an array, 'z' must be given")
        if (any(diff(c(length(x), length(y), length(z))) != 0L)) 
            stop("'x', 'y', and 'z' must have the same length")
        DNAME <- paste(DNAME, "and", deparse(substitute(y)), 
                       "and", deparse(substitute(z)))
        OK <- complete.cases(x, y, z)
        x <- factor(x[OK])
        y <- factor(y[OK])
        if ((nlevels(x) < 2L) || (nlevels(y) < 2L)) 
            stop("'x' and 'y' must have at least 2 levels")
        else x <- table(x, y, z[OK])
    }
    if (any(apply(x, 3L, sum) < 2)) 
        stop("sample size in each stratum must be > 1")
    I <- dim(x)[1L]
    J <- dim(x)[2L]
    K <- dim(x)[3L]
    if ((I == 2) && (J == 2)) {
        alternative <- match.arg(alternative)
        if (!missing(conf.level) && (length(conf.level) != 1 || 
                                     !is.finite(conf.level) || conf.level < 0 || conf.level > 
                                     1)) 
            stop("'conf.level' must be a single number between 0 and 1")
        NVAL <- c(`common odds ratio` = 1)
        if (!exact) {
            s.x <- apply(x, c(1L, 3L), sum)
            s.y <- apply(x, c(2L, 3L), sum)
            n <- as.double(apply(x, 3L, sum))
            DELTA <- sum(x[1, 1, ] - s.x[1, ] * s.y[1, ]/n)
            YATES <- if (correct && (abs(DELTA) >= 0.5)) 
                0.5
            else 0
            STATISTIC <- ((abs(DELTA) - YATES)^2/sum(apply(rbind(s.x, 
                                                                 s.y), 2L, prod)/(n^2 * (n - 1))))
            PARAMETER <- 1
            if (alternative == "two.sided") 
                PVAL <- pchisq(STATISTIC, PARAMETER, lower.tail = FALSE)
            else {
                z <- sign(DELTA) * sqrt(STATISTIC)
                PVAL <- pnorm(z, lower.tail = (alternative == 
                                                   "less"))
            }
            names(STATISTIC) <- "Mantel-Haenszel X-squared"
            names(PARAMETER) <- "df"
            METHOD <- paste("Mantel-Haenszel chi-squared test", 
                            if (YATES) 
                                "with"
                            else "without", "continuity correction")
            s.diag <- sum(as.numeric(x[1L, 1L, ] )* as.numeric(x[2L, 2L, ])/n)
            s.offd <- sum(as.numeric(x[1L, 2L, ]) * as.numeric(x[2L, 1L, ])/n)
            ESTIMATE <- s.diag/s.offd
            sd <- sqrt(sum((as.numeric(x[1L, 1L, ]) + as.numeric(x[2L, 2L, ])) * as.numeric(x[1L, 
                                                                                              1L, ]) * as.numeric(x[2L, 2L, ])/n^2)/(2 * s.diag^2) + sum(((as.numeric(x[1L, 
                                                                                                                                                                        1L, ]) + as.numeric(x[2L, 2L, ])) * as.numeric(x[1L, 2L, ]) * as.numeric(x[2L, 1L, 
                                                                                                                                                                                                                                                   ]) + (as.numeric(x[1L, 2L, ]) + as.numeric(x[2L, 1L, ])) * as.numeric(x[1L, 1L, ]) * 
                                                                                                                                                              as.numeric(x[2L, 2L, ]))/n^2)/(2 * s.diag * s.offd) + sum((as.numeric(x[1L, 
                                                                                                                                                                                                                                      2L, ]) + as.numeric(x[2L, 1L, ])) * as.numeric(x[1L, 2L, ]) * as.numeric(x[2L, 1L, 
                                                                                                                                                                                                                                                                                                                 ])/n^2)/(2 * s.offd^2))
            CINT <- switch(alternative, less = c(0, ESTIMATE * 
                                                     exp(qnorm(conf.level) * sd)), greater = c(ESTIMATE * 
                                                                                                   exp(qnorm(conf.level, lower.tail = FALSE) * sd), 
                                                                                               Inf), two.sided = {
                                                                                                   ESTIMATE * exp(c(1, -1) * qnorm((1 - conf.level)/2) * 
                                                                                                                      sd)
                                                                                               })
            RVAL <- list(statistic = STATISTIC, parameter = PARAMETER, 
                         p.value = PVAL)
        }
        else {
            METHOD <- paste("Exact conditional test of independence", 
                            "in 2 x 2 x k tables")
            mn <- apply(x, c(2L, 3L), sum)
            m <- mn[1L, ]
            n <- mn[2L, ]
            t <- apply(x, c(1L, 3L), sum)[1L, ]
            s <- sum(x[1L, 1L, ])
            lo <- sum(pmax(0, t - n))
            hi <- sum(pmin(m, t))
            support <- lo:hi
            dc <- .Call(C_d2x2xk, K, m, n, t, hi - lo + 1L)
            logdc <- log(dc)
            dn2x2xk <- function(ncp) {
                if (ncp == 1) 
                    return(dc)
                d <- logdc + log(ncp) * support
                d <- exp(d - max(d))
                d/sum(d)
            }
            mn2x2xk <- function(ncp) {
                if (ncp == 0) 
                    return(lo)
                if (ncp == Inf) 
                    return(hi)
                sum(support * dn2x2xk(ncp))
            }
            pn2x2xk <- function(q, ncp = 1, upper.tail = FALSE) {
                if (ncp == 0) {
                    if (upper.tail) 
                        return(as.numeric(q <= lo))
                    else return(as.numeric(q >= lo))
                }
                if (ncp == Inf) {
                    if (upper.tail) 
                        return(as.numeric(q <= hi))
                    else return(as.numeric(q >= hi))
                }
                d <- dn2x2xk(ncp)
                if (upper.tail) 
                    sum(d[support >= q])
                else sum(d[support <= q])
            }
            PVAL <- switch(alternative, less = pn2x2xk(s, 1), 
                           greater = pn2x2xk(s, 1, upper.tail = TRUE), two.sided = {
                               relErr <- 1 + 10^(-7)
                               d <- dc
                               sum(d[d <= d[s - lo + 1] * relErr])
                           })
            mle <- function(x) {
                if (x == lo) 
                    return(0)
                if (x == hi) 
                    return(Inf)
                mu <- mn2x2xk(1)
                if (mu > x) 
                    uniroot(function(t) mn2x2xk(t) - x, c(0, 1))$root
                else if (mu < x) 
                    1/uniroot(function(t) mn2x2xk(1/t) - x, c(.Machine$double.eps, 
                                                              1))$root
                else 1
            }
            ESTIMATE <- mle(s)
            ncp.U <- function(x, alpha) {
                if (x == hi) 
                    return(Inf)
                p <- pn2x2xk(x, 1)
                if (p < alpha) 
                    uniroot(function(t) pn2x2xk(x, t) - alpha, 
                            c(0, 1))$root
                else if (p > alpha) 
                    1/uniroot(function(t) pn2x2xk(x, 1/t) - alpha, 
                              c(.Machine$double.eps, 1))$root
                else 1
            }
            ncp.L <- function(x, alpha) {
                if (x == lo) 
                    return(0)
                p <- pn2x2xk(x, 1, upper.tail = TRUE)
                if (p > alpha) 
                    uniroot(function(t) pn2x2xk(x, t, upper.tail = TRUE) - 
                                alpha, c(0, 1))$root
                else if (p < alpha) 
                    1/uniroot(function(t) pn2x2xk(x, 1/t, upper.tail = TRUE) - 
                                  alpha, c(.Machine$double.eps, 1))$root
                else 1
            }
            CINT <- switch(alternative, less = c(0, ncp.U(s, 
                                                          1 - conf.level)), greater = c(ncp.L(s, 1 - conf.level), 
                                                                                        Inf), two.sided = {
                                                                                            alpha <- (1 - conf.level)/2
                                                                                            c(ncp.L(s, alpha), ncp.U(s, alpha))
                                                                                        })
            STATISTIC <- c(S = s)
            RVAL <- list(statistic = STATISTIC, p.value = PVAL)
        }
        names(ESTIMATE) <- names(NVAL)
        attr(CINT, "conf.level") <- conf.level
        RVAL <- c(RVAL, list(conf.int = CINT, estimate = ESTIMATE, 
                             null.value = NVAL, alternative = alternative))
    }
    else {
        df <- (I - 1) * (J - 1)
        n <- m <- double(length = df)
        V <- matrix(0, nrow = df, ncol = df)
        for (k in 1:K) {
            f <- x[, , k]
            ntot <- sum(f)
            rowsums <- apply(f, 1L, sum)[-I]
            colsums <- apply(f, 2L, sum)[-J]
            n <- n + c(f[-I, -J])
            m <- m + c(outer(rowsums, colsums, "*"))/ntot
            V <- V + (kronecker(diag(ntot * colsums, nrow = J - 
                                         1) - outer(colsums, colsums), diag(ntot * rowsums, 
                                                                            nrow = I - 1) - outer(rowsums, rowsums))/(ntot^2 * 
                                                                                                                          (ntot - 1)))
        }
        n <- n - m
        STATISTIC <- c(crossprod(n, qr.solve(V, n)))
        PARAMETER <- df
        PVAL <- pchisq(STATISTIC, PARAMETER, lower.tail = FALSE)
        names(STATISTIC) <- "Cochran-Mantel-Haenszel M^2"
        names(PARAMETER) <- "df"
        METHOD <- "Cochran-Mantel-Haenszel test"
        RVAL <- list(statistic = STATISTIC, parameter = PARAMETER, 
                     p.value = PVAL)
    }
    RVAL <- c(RVAL, list(method = METHOD, data.name = DNAME))
    class(RVAL) <- "htest"
    return(RVAL)
}


table.maker<-function(x){
    # Input:
    # x = treatment indicator
    # Output:
    # table of descriptive statistics and tests
    
    
    # Difference of Proportions
     test<-stats::prop.test(table(x,wrkdat$subscribed)[,c(2,1)])
     diff<- sprintf("%.4f",round(test$estimate[1]-test$estimate[2],4))
     pval<- sprintf("%.4f",round(test$p.value,4))
    # MH Test using BatchDay
    mhtest<-my.mantelhaen.test(table(x,wrkdat$subscribed,wrkdat$batchday2F))
    mhtest.pval<-sprintf("%.4f",round(mhtest$p.value,4))
    mhtest.stat<-sprintf("%.4f",round(mhtest$statistic,4))
    mhtest.or<-sprintf("%.4f",round(mhtest$estimate,4))
    mhtest.or.ci<-paste("[",paste(round(mhtest$conf.int,3),collapse = "; "),"]",sep="")
    # 
    cmh_approx<-cmh_test(subscribedF~x|batchday2F,data=wrkdat,distribution=approximate(B=1000))
    cmh_approx.stat<-sprintf("%.4f",statistic(cmh_approx))
    cmh_approx.pval<-sprintf("%.4f",pvalue(cmh_approx))
    
    
    tab<-rbind(table(x),
            table(wrkdat$subscribed,x),
            paste("**",round(unlist(lapply(split(wrkdat$subscribed,f=x),mean)),4),"**",sep=""),c(" "," "),
            c("*Statistic*","*p-value [CI]*"),
            c(diff,pval),
            c( mhtest.stat,mhtest.pval),
            c(cmh_approx.stat,cmh_approx.pval),
            c( mhtest.or,mhtest.or.ci)
            )
    rownames(tab)<-c("**Sample**","Subscribed","Not Subscribed","Proportion Subscribing","___","**Test**","Difference in Proportions","CMH Test","Approx CMH Test  ","Common Odds Ratio")
    colnames(tab)<-paste("**",colnames(tab),"**",sep="")
    return(tab)


}

```


## A,C,E versus B,D,F (a test of opt-in versus enhanced active).

```{r tabbdf,results="asis"}
tab_bdf<-table.maker(wrkdat$treat_bdf)
kable(tab_bdf,caption="Enhanced Active versus Single Opt-In")
```

# A,B,C,D versus E,F (a test of Block of 10 present versus active)

```{r tababcd,results="asis"}
# A,B,C,D versus E,F (a test of Block of 10 present versus active)

tab_abcd<-table.maker(wrkdat$treat_abcd)
kable(tab_abcd,caption="Block of 10 Present or Absent")


```

# A,B versus C,D (a test of list versus quiz format)

```{r tabab,results="asis"}
# A,B versus C,D (a test of list versus quiz format)

tab_ab<-table.maker(wrkdat$treat_ab)
kable(tab_ab)

```


# Assess sensitivity of the results to different ways of distributing unmatched cases

The table below shows the number of unmatched cases by batch day in the list of subscribers (i.e. people shown as suscribing who we were unable to match to the experimental pool by either email, full name, or last name).

```{r unmatch}
# List of unmatchables by batch day
unmatchables<-data.frame(batchday2=sort(unique(wrkdat$batchday2)),
             count=c(24,6,14,33,20,24,19,38,8,18,8,99,14,23,20,48,16,12,22,44,16,53,12,26,40,13,64,23,54,24,29,15,52,10,11,65,22,25,40,10,81))

tab_unmatch<-unmatchables
colnames(tab_unmatch)<-c("Batch","Unmatched Cases")
kable(tab_unmatch,caption="Unmatched cases by batch")
```

It is possible that these unmatched cases represent "successful" interventions, however in the analysis above, they were treated as "failueres" (i.e. non-subscribers). In this section, we assess the consequences of that assumption through a series of simulations that ask what would our results look like had we been able to match these subscribers to members of the experimental pool.

The code below generates a simulated dataset, in which, for each batch, are randomly assigned as being subscribers. 

```{r sensitivity}
# 
# Function to randomly reassign unmatched cases by batch day
data_fn<-function(x="treatmentF"){
    # Split data in subscribers and non subscribers
    newdat<-wrkdat[,c("subscribedF","batchday2F",x)]
    newdat<-newdat[order(newdat$batchday2F),]
    newdat_1<-newdat[newdat$subscribed==1,]
    newdat_1$subscribed_bnd<-newdat_1$subscribed
    newdat_0<-newdat[newdat$subscribed==0,]
    batch_assign_fn<-function(batch,size){
x<-newdat_0$subscribed[newdat_0$batchday2F==batch]
x<-replace(newdat_0$subscribed[newdat_0$batchday2F==batch],sample(1:length(newdat_0$subscribed[newdat_0$batchday2F==batch]),size),1)
return(x)
}
    newdat_0$subscribed_bnd<-unlist(mapply(batch_assign_fn,batch=unmatchables[,1],size=unmatchables[,2]))
    stopifnot(table(newdat_0$subscribed_bnd,newdat_0$batchday2F)[2,]==unmatchables[,2])
    # Recombine
    newdat<-rbind(newdat_1,newdat_0)
    return(newdat)
}
```

So for example, we know that in the first batch, 24 cases in the subscribe list are unmatchable. In the each simulated dataset 24 cases in batch 1 are randomly assigned to be treated. In the code below, we see one simulation where for batch 1, treatment groups A and B receive three extra subscribers, C recieves five, D four, E seven, and F two.




```{r examp}
set.seed(123)
example.df<-data_fn()
with(wrkdat,table(subscribedF,batchday2F))
with(example.df,table(subscribed_bnd,batchday2F))

# Change in subscribers for batch 1 in 1 simulation
with(example.df[example.df$batchday2F==1,],table(subscribed_bnd,treatmentF))-
with(wrkdat[wrkdat$batchday2F==1,],table(subscribedF,treatmentF))



     
```

Next we generate 1000 simulated datasets. Each time the unmatched cases in each batch are randomly assigned to be subscribers. For each simulated dataselt, we re-run the tests above (namely the generalized CMH tests and the Tukey HSD test pairwise comparisons) and save the results. 


```{r cmhSim,results="asis"}

# Set seed
set.seed(123)
# Number of simulations
nsim<-1000 

# Function to Simulate CMH Tests

sim_cmh_fn<-function(treat){
    # Generate data
    df<-data_fn(x=treat)
    # Write formula 
    f <- reformulate(paste(treat,"|batchday2F"),response="subscribed_bnd")
    # CMH Test, use asymptotic results for now for now
    cmh<-cmh_test(f,data=df)
    # Collect test stat and pvalue
    stat<-statistic(cmh)
    pval<-pvalue(cmh)
    return(cbind(stat,pval))
}



# Use mosaic's do wrapper
## library(mosaic)

sim_cmh_all<-do(nsim)*sim_cmh_fn(treat="treatmentF")
sim_cmh_all$Comparison<-"All Treatments"
sim_cmh_bdf<-do(nsim)*sim_cmh_fn(treat="treat_bdf")
sim_cmh_bdf$Comparison<-"BDF vs ACE"
sim_cmh_abcd<-do(nsim)*sim_cmh_fn(treat="treat_abcd")
sim_cmh_abcd$Comparison<-"ABCD vs EF"
sim_cmh_ab<-do(nsim)*sim_cmh_fn(treat="treat_ab")
sim_cmh_ab$Comparison<-"AB vs CD"

# Combine results for plotting and summary
sim_cmh<-rbind(
    sim_cmh_all,
    sim_cmh_bdf,
    sim_cmh_abcd,
    sim_cmh_ab
    
)
sim_cmh$Comparison<-factor(sim_cmh$Comparison,levels=c("All Treatments",
                                                       "BDF vs ACE",
                                                       "ABCD vs EF",
                                                       "AB vs CD"
                                                       ))
# Percent of tests yielding significant differnces
library(plyr)
tab_sim_cmh<-ddply(sim_cmh,.(Comparison),summarize,
                   Percent=mean(pval<0.05)*100
                   
                   )
kable(tab_sim_cmh[,c("Comparison","Percent")],
      caption ="Percent of Simulations Yielding Significant Difference" )
```


```{r figCMHsim}
p_sim_cmh_all<-ggplot(sim_cmh,aes(pval))+geom_density(bw=1/2000)+geom_rug()+facet_wrap(~Comparison)+labs(title="Distribution of p-values from CMH simulations")
p_sim_cmh_all


```


```{r tukeySim}
# Simulate Tukey Comparisons

sim_tukey_fn<-function(treat="treatmentF"){
    df<-data_fn(x=treat)
    df$subscribed_bnd<-as.numeric(df$subscribed_bnd)
    df$sBatchAve<-ave(df$subscribed_bnd,df$batchday2F)
    a1<-aov(I(subscribed_bnd-sBatchAve)~treatmentF,df)
    tukey<-data.frame(TukeyHSD(a1)$treatmentF)
    tukey$Comparison<-factor(rownames(tukey),levels=rev(rownames(tukey)))
    return(tukey)
}
sim_tukey<-do(nsim)*sim_tukey_fn()
library(plyr)
```

```{r tukeytab,results="asis"}
sim_tukey_df<-ddply(sim_tukey,.(Comparison),summarize,
                    diff=mean(diff),
                    lwr=mean(lwr),
                    upr=mean(upr),
                    Percent=mean(p.adj<.05)*100
                    )

kable(sim_tukey_df[,c("Comparison","Percent")],
      caption ="Percent of Simulations Yielding Significant Difference" )

```

```{r figTukeypval}
p_pw_pval_sim<-ggplot(sim_tukey,aes(p.adj,col=Comparison))+geom_density(bw=1/100)+facet_wrap(~ Comparison)+geom_rug()+labs(x=paste(nsim,"simulated p-values from pairwise comparison"),title="Distribution of p-values from Tukey HSD simulations")
p_pw_pval_sim
```

```{r figTukeycoef}
p_tukey_sim<-ggplot(sim_tukey_df,aes(y=Comparison,x=diff))+
    geom_vline(xintercept=0,linetype = 2,col="red")+
    geom_errorbarh(aes(xmin=lwr,xmax=upr),height=.25,col="grey")+
        geom_point()+ labs(x="Difference in proportions",title="95% family-wise confidence level from Tukey HSD Simulations")

p_tukey_sim



```

# Extreme Bounds

Finally we briefly examine the results from randomly assigning all 1,195 unmatched cases to each of the six treatment conditions, again respecting the distribution of unmatched cases by batch. In essence this increases the proportion of subscribers in each condition by `r round(1195/sum(wrkdat$treatment=="A"),3)`--over a 100 percent increase. Depending on the treatment group, this is enough to reverse sign on each of our subgroup comparisons.

```{r ext}
# function to reassign all unmatched cases by batch to a specific treatment
1195/sum(wrkdat$treatment=="A")
data_fn2<-function(x="treatmentF",group="A"){
   tmp<-wrkdat[,c("subscribedF","batchday2F","treatment",x)]
   #
   same<-tmp[tmp$treatment!=group,]
   same$subscribed_bnd<-same$subscribedF
   new<-tmp[tmp$treatment==group,]
   new$subscribed_bnd<-new$subscribedF
   new1<-new[new$subscribedF==1,]
   new0<-new[new$subscribedF==0,]
   batch_assign_fn<-function(batch,size){
x<-new0$subscribed[new0$batchday2F==batch]
x<-replace(new0$subscribedF[new0$batchday2F==batch],sample(1:length(new0$subscribedF[new0$batchday2F==batch]),size),1)
return(x)
}
    new0$subscribed_bnd<-unlist(mapply(batch_assign_fn,batch=unmatchables[,1],size=unmatchables[,2]))
    dat<-rbind(same,new1,new0)
    return(dat)
}

# Extreme Proporitions

ext_fn<-function(the.treat="treatmentF",the.group="A"){
    df<-data_fn2(x=the.treat,group=the.group)
    old<-unlist(lapply(split(wrkdat$subscribed,f=wrkdat[,the.treat]),function(x){mean(x==1)}))
     new<-unlist(lapply(split(df$subscribed_bnd,f=df[,the.treat]),function(x){mean(x==1)}))
    return(rbind(old,new))

}
apply(ext_fn(the.treat="treatmentF"),2,diff)
ext_fn(the.treat="treat_bdf")
ext_fn(the.treat="treat_abcd")
ext_fn(the.treat="treat_ab")

mean(wrkdat$subscribed)


 

extreme_cmh_fn<-function(the.treat="treatmentF",the.group="A"){
    df<-data_fn2(x=the.treat,group=the.group)
    f <- reformulate(paste(the.treat,"|batchday2F"),response="subscribed_bnd")
    # CMH Test, use asymptotic results for now for now
    cmh<-cmh_test(f,data=df)
    return(cmh)
    
    
}


ext_cmh_gen_A<-extreme_cmh_fn(the.group="A")
ext_cmh_gen_B<-extreme_cmh_fn(the.group="B")
ext_cmh_gen_C<-extreme_cmh_fn(the.group="C")
ext_cmh_gen_D<-extreme_cmh_fn(the.group="D")
ext_cmh_gen_E<-extreme_cmh_fn(the.group="E")
ext_cmh_gen_F<-extreme_cmh_fn(the.group="F")

# All of the general tests remain significant
# ACE vs BDF # 
ext_cmh_bdf_A<-extreme_cmh_fn(the.treat="treat_bdf",the.group="A")
ext_cmh_bdf_B<-extreme_cmh_fn(the.treat="treat_bdf",the.group="B")
ext_cmh_bdf_C<-extreme_cmh_fn(the.treat="treat_bdf",the.group="C")
ext_cmh_bdf_D<-extreme_cmh_fn(the.treat="treat_bdf",the.group="D")
ext_cmh_bdf_E<-extreme_cmh_fn(the.treat="treat_bdf",the.group="E")
ext_cmh_bdf_F<-extreme_cmh_fn(the.treat="treat_bdf",the.group="F")

# Benefits (ABCD) vs No Benefits (EF)
ext_cmh_abcd_A<-extreme_cmh_fn(the.treat="treat_abcd",the.group="A")
ext_cmh_abcd_B<-extreme_cmh_fn(the.treat="treat_abcd",the.group="B")
ext_cmh_abcd_C<-extreme_cmh_fn(the.treat="treat_abcd",the.group="C")
ext_cmh_abcd_D<-extreme_cmh_fn(the.treat="treat_abcd",the.group="D")
ext_cmh_abcd_E<-extreme_cmh_fn(the.treat="treat_abcd",the.group="E")
ext_cmh_abcd_F<-extreme_cmh_fn(the.treat="treat_abcd",the.group="F")

# List (AB) vs Quiz (CD)
ext_cmh_ab_A<-extreme_cmh_fn(the.treat="treat_ab",the.group="A")
ext_cmh_ab_B<-extreme_cmh_fn(the.treat="treat_ab",the.group="B")
ext_cmh_ab_C<-extreme_cmh_fn(the.treat="treat_ab",the.group="C")
ext_cmh_ab_D<-extreme_cmh_fn(the.treat="treat_ab",the.group="D")
ext_cmh_ab_E<-extreme_cmh_fn(the.treat="treat_ab",the.group="E")
ext_cmh_ab_F<-extreme_cmh_fn(the.treat="treat_ab",the.group="F")
```

# Code Appendix

```{r appendix, eval=F,echo=T}
<<setup>>
<<dv>>
<<cmh>>
<<fig1>>
<<TukeyHSD>>
<<figTukey>>
<<subgroup>>
<<tabbdf>>
<<tababcd>>
<<tabab>>
<<unmatch>>
<<sensitivity>>
<<examp>>
<<cmhSim>>
<<figCMHsim>>
<<tukeySim>>
<<tukeytab>>
<<figTukeypval>>
<<figTukeycoef>>
<<ext>>
```

