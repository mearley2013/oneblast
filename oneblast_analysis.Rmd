---
title: "DoD Military Community and Family Policy Military OneSource eNewsletter"
author: "Paul Testa and Jake Bowers"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
html_document:
toc: TRUE
---

```{r init,echo=F}
## Easy way to look for and install missing packages and load them
if (!require("pacman")){ install.packages("pacman") }
pacman::p_load("knitr","openssl","mosaic","plyr","coin","ggplot2")
## library(knitr)
opts_chunk$set(eval=T,echo=F,results="hide",message=F,warning=F,cache=T)
options(digits=4,width=100,scipen=8)

```

\tableofcontents

# Setup

- Download "wrkdat.csv" onto local machine in the data subdirectory
- Load files and libaries

```{r setup}
wrkdat<-read.csv("data/wrkdat.csv",as.is=TRUE)
```

The outcome is whether or not a member of the experimental pool subscribed to the newsletter. We currently assume that all members of the experimental pool who have a 0 for subscribed did not subscribe under a different name and email address. We return to scrutinize the effect of this assumption later.

```{r dv}
# Subscribed is the primary outcome
table(wrkdat$subscribed,exclude=c())
## Make some variables into factors for contingency table analysis
wrkdat$batchday2F<-factor(wrkdat$batchday2)
wrkdat$treatmentF<-factor(wrkdat$treatment)
wrkdat$subscribedF<-factor(wrkdat$subscribed)
```

Because the experiment was randomized by batch, and because of trouble matching subscribers uniquely to the experimental pool, we analyze the data by a collapsed version of the 82 batch indicators that we call `batchday`. Nearly all batches were sent 2 per day and the subscriber data only has day of subscription, not hour or minute. This choice, to make new experimental blocks from the original ones will decrease statistical power, but, because the blocks were basically the same size, and because we take blocking into account when we calculate estimates, our estimates will be unbiased.

Do we have enough information to reject the claim that there are no differences between the treatments? We use the generalized Cochran-Mantel-Haensel test to address this question. We are using the coin library because it allows for easy assessment of this test without large sample assumptions by simulating from the reference distribution implied by the experiment itself.

```{r cmh}
library(coin)

cmh1approx<-cmh_test(subscribedF~treatmentF|batchday2F,data=wrkdat,distribution=approximate(B=1000))
cmh1<-cmh_test(subscribedF~treatmentF|batchday2F,data=wrkdat)

bigtab<-with(wrkdat,table(treatmentF,subscribed,batchday2F))
cmh2 <- mantelhaen.test(bigtab)

c(pvalue(cmh1),pvalue(cmh1approx)[[1]],cmh2$p.value)
```

There is a lot of evidence against the idea that all six emails had the same effect and, despite the rareness of the outcome, the substantive interpretation of the test is the same whether or not we rely on large sample assumptions or sample directly from the randomization distribution.

# Estimate Difference of Proportions

Now we'll start to draw comparisons between specific treatments and groups of treatments.

In the figure below we show the proportions subscribing in each treatment group with 95-percent confidence intervals. Treatments B and F appear to be the most successful at encouraging subscription to the newsletter. Because treatment was assigne by block, our overall estimates of proportions are weighted by the size of the block. Here, we follow @lin2013agnostic and the [Green Lab Standard Operating Procedure](https://github.com/acoppock/Green-Lab-SOP) calculating these quantities.

Block randomized experiments require that the estimand be defined with respect to a scheme for weighting the contributions of the different block-specific estimates, and an estimator which is unbiased (or at least consistent) for that estimand. In this case, we have two possible estimands:
When block sizes vary and especially when the proportion treated per block varies greatly, one can substantially increase precision by estimating using what are known as harmonic weights. In this case, with more or less equal sized blocks (40 out of 41 are equal), and more or less equal proportions, we use the simple block size weighting.

```{r eval=FALSE, echo=FALSE, include=FALSE}
## Harmonic Mean weighted estimates of the proportions
lm1<-lm(subscribed~treatment+batchday2F,data=wrkdat)
coef(lm1)[1:10]
propsw<- c(treatmentA=coef(lm1)[[1]],coef(lm1)[1]+coef(lm1)[2:6])
propsw
```

Lin (2011,2013) says that block size weighting can be done via a least squares
linear model. Here, we use a small subset of the data to show that this is so.
We do this to take advantage of some easy to implement ways to get p-values and
confidence intervals after linear model estimation.

## Test that we can recover block size weighted quantites from least squares

```{r}
## Batch size weighting

### Verifying code using only 3 strata
wrkdatsmall<-droplevels(wrkdat[wrkdat$batchday2 %in% c(1,2,3),c("subscribed","treatmentF","batchday2F")])

tausbyhand<-function(dat,block,treatment,outcome){
	##block is a factor indicating block membership
	##treatment is factor indicating treatment assignment
	##outcome is numeric (could be binary or continuous)
	##dat is a data.frame or matrix
	prop_b<-table(dat[,block])/nrow(dat)
	tau_b<-sapply(split(dat,dat[,block]),function(blockdat){
			      sapply(levels(blockdat[,treatment]),function(i){
					     mean(blockdat[,outcome][blockdat[,treatment]==i]) }) })
	tau_bw<-apply(tau_b[,names(prop_b)],1,function(x){ x[names(prop_b)]*prop_b})
	stopifnot(all.equal(tau_b[,"3"]*prop_b["3"], tau_bw["3",]))
	taus<-colSums(tau_bw)
	return(taus)
}

taus<-tausbyhand(dat=wrkdatsmall,block="batchday2F",treatment="treatmentF",outcome="subscribed")


## Now try this using lm()
prop_b<-table(wrkdatsmall$batchday2F)/nrow(wrkdatsmall)
B <- model.matrix(~batchday2F+0,data=wrkdatsmall)
Bmd <- sapply(1:ncol(B),function(i){ B[,i] - prop_b[i] }) ## subtract off proportion in B
colnames(Bmd)<-colnames(B)
wrkdatsmall[,colnames(Bmd)]<-Bmd

bigfmla<-as.formula(paste("subscribed~treatmentF*(",paste(colnames(Bmd)[-1],collapse="+"),")"))

lm2<-lm(bigfmla,data=wrkdatsmall)
coef(lm2)[1:10]
propswInter<- c(treatmentA=coef(lm2)[[1]],coef(lm2)[1]+coef(lm2)[2:6])
propswInter
taus
stopifnot(all.equal(taus,propswInter,check.attributes=FALSE))

## THe mean of the batch factor indicators is 0 by construction, this is why we can interpret the coefs on treatmentF as telling us about an average across the batches. This next shows this.
newdat<- expand.grid(treatmentF=levels(wrkdatsmall$treatmentF), batchday2F2=c(0), batchday2F3=c(0))
propsInter2<-predict(lm2,newdata=newdat)
stopifnot(all(propsInter2-propswInter==0))
stopifnot( all(abs(taus - propsInter2) < 1e-10) ) ## funny floating point differences

rm(B,Bmd,bigfmla,propswInter,newdat,propsInter2)
```

Now create the proportions using the whole dataset.

```{r}
## Batch size weighting

realtaus<-tausbyhand(dat=wrkdat,block="batchday2F",treatment="treatmentF",outcome="subscribed")

## Now try this using lm()
prop_b<-table(wrkdat$batchday2F)/nrow(wrkdat)
B <- model.matrix(~batchday2F+0,data=wrkdat)
Bmd <- sapply(1:ncol(B),function(i){ B[,i] - prop_b[i] })
colnames(Bmd)<-colnames(B)
wrkdat[,colnames(Bmd)]<-Bmd

bigfmla<-as.formula(paste("subscribed~treatmentF*(",paste(colnames(Bmd)[-1],collapse="+"),")"))

lm2<-lm(bigfmla,data=wrkdat)
coef(lm2)[1:10]
estprops<- c(treatmentA=coef(lm2)[[1]],coef(lm2)[1]+coef(lm2)[2:6])
estprops
realtaus
stopifnot(all.equal(realtaus,estprops,check.attributes=FALSE))
```

We get the CIs using the HC2 based standard errors following the development in Lin 2011 etc..

```{r}
library(sandwich)
library(lmtest)
source("confintHC.R")

## This next shows that we can get the same answers as suggested by Lin if we don't exclude a level of treatment.
lm3<-lm(update(bigfmla,.~+batchday2F1-1+.),data=wrkdat)
lm3props<-coef(lm3)[grep("treatment.[A-F]$",names(coef(lm3)))]
stopifnot(all(abs(lm3props-estprops)<1e-10))

theCIs<-confint(lm3,parm=names(lm3props),vcov=vcovHC(lm3,type="HC2"))

```


```{r fig1}
theprops<-data.frame(estprops,theCIs)
# Add names and Treatment indicator
colnames(theprops)<-c("pbar","ll","ul")
row.names(theprops)<- c('A','B','C','D','E','F')
theprops$Treatment<-c("Opt-in; List", # A
		      "Active; List", # B
		      "Opt-in; Quiz", # C
		      "Active; Quiz", # D
		      "Opt-in",       # E
		      "Active"        # F
		      )
theprops$Treatment <- factor(theprops$Treatment, levels=theprops$Treatment[order(theprops$pbar)])

# Plot with ggplot2
## library(ggplot2)
dodge<-position_dodge(width = 0.9)
p.props<-ggplot(theprops,aes(Treatment,pbar,fill=Treatment))+
	geom_bar(stat = "identity", position = dodge)+
	geom_errorbar(aes(ymin=ll,ymax=ul),position = dodge,width=.25)+
	labs(list(y="Proportion Subscribing to Newsletter",
		  title="Proportion Subscribing by Treatment Group"))+
theme(axis.text.x = element_blank(),axis.ticks.x = element_blank())
p.props
```

Next we provide a more formal assessment of the 15 pairwise comparisons by conducting a Tukey Honest Signficant Differences test on an ANOVA model weighted by the size of each batch, with family-wise confidence intervals that reflect the fact that we are making multiple comparisons.

```{r tukeyHSD}
# Anova weighted by size of batch
a1<-aov(formula(lm3),wrkdat)
coef(a1)[names(lm3props)]
thsda1<-TukeyHSD(a1,which="treatmentF")
```

We see from the next figure that `r sum(thsda1$treatmentF[,4]<0.05)` out of the `r choose(6,2)` pairwise comparisons are statistically distinguishable from 0 ($p<0.05$). Specifically, the effects for Treatment F are significantly larger than any other treatment except Treatment B --- and there the 95% confidence interval just barely includes 0. The effect for Treatment B, although larger than the remaining Treatments (A,C,D and E) is only distinguishable from Treatment C.

```{r figTukey}
# Get estimates and intervals
tukey<-data.frame(thsda1$treatmentF)
##plot(TukeyHSD(a1))
tukey$Comparison<-factor(rownames(tukey),levels=rev(rownames(tukey)))
tukey$Comparison<-factor(tukey$Comparison,levels=tukey$Comparison[order(tukey$diff)])

p.tukey<-ggplot(tukey,aes(y=Comparison,x=diff))+
	geom_vline(xintercept=0,linetype = 2,col="red")+
	geom_errorbarh(aes(xmin=lwr,xmax=upr),height=.25,col="grey")+
	geom_point()+
	labs(x="Difference in proportions",title="95% family-wise confidence level")
p.tukey
```

# Tests differences in the prespecified subgroups of treatments

This section makes the following comparisons:

- A,C,E versus B,D,F (a test of opt-in versus enhanced active).
- A,B,C,D versus E,F (a test of Block of 10 present versus absent)
- A,B versus C,D (a test of list versus quiz format)

To make life easier, we'll create indicators of these groupings, write a function to conduct generalized Cochran-Mantel-Haensel tests of these differences, accounting for batch^[We also need to fix some code in the mantelhaen.test to tell R to treat integers as floating point values]

```{r subgroup}
# A,C,E versus B,D,F (a test of opt-in versus enhanced active).
wrkdat$treat_bdf_01<-as.numeric(grepl("B|D|F",wrkdat$treatment))
wrkdat$treat_bdf<-factor(ifelse(grepl("B|D|F",wrkdat$treatment),"Enhanced Active","Opt-In"))
table(wrkdat$treat_bdf)
# A,B,C,D versus E,F (a test of Block of 10 present versus active)
wrkdat$treat_abcd_01<-as.numeric(grepl("A|B|C|D",wrkdat$treatment))
wrkdat$treat_abcd<-ifelse(grepl("A|B|C|D",wrkdat$treatment),"Present","Absent")
wrkdat$treat_abcd<-factor(wrkdat$treat_abcd,levels=c("Present","Absent"))

# A,B versus C,D (a test of list versus quiz format)
wrkdat$treat_ab_01<-as.numeric(grepl("A|B",wrkdat$treatment))
wrkdat$treat_ab_01[!grepl("A|B|C|D",wrkdat$treatment)]<-NA
wrkdat$treat_ab<-factor(ifelse(wrkdat$treat_ab_01==1,"List","Quiz"))

# Use an updated mantel-haenszel test so it can calculate CIs for odds ratio
source("mymantelhaentest.R")

table.maker<-function(x,xnm=NULL,asymp=TRUE){
	# Input:
	# x = treatment indicator
	# xnm = character name of treatment indicator in wrkdat
	# asymp = logical scale indicating whether asymptotic results should be used

	# Output:
	# table of descriptive statistics and tests

	# Difference of Proportions
	## The asymp version is almost same as the HC2 version below
	oneway_approx <- oneway_test(as.formula(paste("subscribed~",xnm,"|batchday2F",collapse="")),data=wrkdat,distribution=approximate(B=1000))
	#oneway_asymp <- oneway_test(as.formula(paste("subscribed~",xnm,"|batchday2F",collapse="")),data=wrkdat,distribution=asymptotic())
	oneway_approx.stat<-sprintf("%.4f",statistic(oneway_approx))
	oneway_approx.pval<-sprintf("%.4f",pvalue(oneway_approx))
	#oneway_asymp.stat<-sprintf("%.4f",statistic(oneway_asymp))
	#oneway_asymp.pval<-sprintf("%.4f",pvalue(oneway_asymp))

	## Diff of proportions
	thefmla<-as.formula(paste("subscribed~",xnm,"*(",paste(colnames(Bmd)[-1],collapse="+"),")"))
	thelm<-lm(thefmla,data=wrkdat)
	thediff<-coef(thelm)[grep(":",grep(xnm,names(coef(thelm)),value=TRUE),invert=TRUE,value=TRUE)]
	theCI<-confint.HC(thelm,parm=names(thediff),thevcov=vcovHC(thelm,type="HC2"))
	thepval <- coeftest(thelm,vcov=vcovHC(thelm,type="HC2"))[names(thediff),"Pr(>|t|)"]

	# MH Test using BatchDay
	mhtest<-my.mantelhaen.test(table(x,wrkdat$subscribed,wrkdat$batchday2F))
	mhtest.pval<-sprintf("%.4f",round(mhtest$p.value,4))
	mhtest.stat<-sprintf("%.4f",round(mhtest$statistic,4))
	mhtest.or<-sprintf("%.4f",round(mhtest$estimate,4))
	mhtest.or.ci<-paste("[",paste(round(mhtest$conf.int,3),collapse = "; "),"]",sep="")
	# Cochran-Mantel-Haenszel Test approximative (i.e. doesn't rely on large sample assumptions)
	cmh_approx<-cmh_test(subscribedF~x|batchday2F,data=wrkdat,distribution=approximate(B=1000))
	cmh_approx.stat<-sprintf("%.4f",statistic(cmh_approx))
	cmh_approx.pval<-sprintf("%.4f",pvalue(cmh_approx))

	tab<-rbind(table(x),
		   table(wrkdat$subscribed,x),
		   paste("**",round(unlist(lapply(split(wrkdat$subscribed,f=x),mean)),4),"**",sep=""),c(" "," "),
		   c("*Statistic*","*p-value [CI]*"),
		   c(sprintf("%.4f",thediff),sprintf("%.4f",thepval)),
		   c("",paste("[",paste(round(theCI,3),collapse=";"),"]",sep="")),
		   c( mhtest.stat,mhtest.pval),
		   c(cmh_approx.stat,cmh_approx.pval),
		   c( mhtest.or,mhtest.or.ci)
		   )

	rownames(tab)<-c("**Sample**","Not Subscribed","Subscribed",
			 "Proportion Subscribing","___","**Test**",
			 "Difference in Proportions",
			 "Difference in Proportions",
			 "CMH Test",
			 "Approx CMH Test  ",
			 "Common Odds Ratio")

	colnames(tab)<-paste("**",colnames(tab),"**",sep="")
	return(tab)
}

```


## A,C,E versus B,D,F (a test of opt-in versus enhanced active).

```{r tabbdf,results="asis"}
tab_bdf<-table.maker(wrkdat$treat_bdf,"treat_bdf")
kable(tab_bdf,caption="Enhanced Active versus Single Opt-In")
```

# A,B,C,D versus E,F (a test of Block of 10 present versus active)

```{r tababcd,results="asis"}
# A,B,C,D versus E,F (a test of Block of 10 present versus active)

tab_abcd<-table.maker(wrkdat$treat_abcd,"treat_abcd")
kable(tab_abcd,caption="Block of 10 Present or Absent")


```

# A,B versus C,D (a test of list versus quiz format)

```{r tabab,results="asis"}
# A,B versus C,D (a test of list versus quiz format)

tab_ab<-table.maker(wrkdat$treat_ab,"treat_ab")
kable(tab_ab)

```


# Assess sensitivity of the results to different ways of distributing unmatched cases

The table below shows the number of unmatched cases by batch day in the list of subscribers (i.e. people shown as suscribing who we were unable to match to the experimental pool by either email, full name, or last name).

```{r unmatch}
# List of unmatchables by batch day
unmatchables<-data.frame(batchday2=sort(unique(wrkdat$batchday2)),
			 count=c(24,6,14,33,20,24,19,38,8,18,8,99,14,23,20,48,16,12,22,44,16,53,12,26,40,13,64,23,54,24,29,15,52,10,11,65,22,25,40,10,81))

tab_unmatch<-unmatchables
colnames(tab_unmatch)<-c("Batch","Unmatched Cases")
kable(tab_unmatch,caption="Unmatched cases by batch")
```

It is possible that these unmatched cases represent "successful" interventions
(i.e. people who subscribed to the newsletter because of the emails), however
in the analysis above, they were treated as "failures" (i.e. non-subscribers).
In this section, we assess the consequences of that assumption through a series
of simulations that ask what would our results look like had we been able to
match these subscribers to members of the experimental pool.

To set bounds on our results we briefly examine the results from randomly
assigning all 1,195 unmatched cases to each of the six treatment conditions,
while respecting the distribution of unmatched cases by batch. In essence this
increases the proportion of subscribers in each condition by `r
round(1195/sum(wrkdat$treatment=="A"),3)`--over a 100 percent increase.
Depending on the treatment group, this is enough to reverse sign on each of our
subgroup comparisons.

```{r ext}
# function to reassign all unmatched cases by batch to a specific treatment
1195/sum(wrkdat$treatment=="A")

data_fn2<-function(x="treatmentF",group="A"){
	tmp<-wrkdat[,c("subscribedF","batchday2F","treatment",x)]
	#
	same<-tmp[tmp$treatment!=group,]
	same$subscribed_bnd<-same$subscribedF
	new<-tmp[tmp$treatment==group,]
	new$subscribed_bnd<-new$subscribedF
	new1<-new[new$subscribedF==1,]
	new0<-new[new$subscribedF==0,]
	batch_assign_fn<-function(batch,size){
		x<-new0$subscribed[new0$batchday2F==batch]
		x<-replace(new0$subscribedF[new0$batchday2F==batch],sample(1:length(new0$subscribedF[new0$batchday2F==batch]),size),1)
		return(x)
	}
	new0$subscribed_bnd<-unlist(mapply(batch_assign_fn,batch=unmatchables[,1],size=unmatchables[,2]))
	dat<-rbind(same,new1,new0)
	return(dat)
}

# Extreme Proporitions

ext_fn<-function(the.treat="treatmentF",the.group="A"){
	df<-data_fn2(x=the.treat,group=the.group)
	old<-unlist(lapply(split(wrkdat$subscribed,f=wrkdat[,the.treat]),function(x){mean(x==1)}))
	new<-unlist(lapply(split(df$subscribed_bnd,f=df[,the.treat]),function(x){mean(x==1)}))
	return(rbind(old,new))
}
apply(ext_fn(the.treat="treatmentF"),2,diff)
ext_fn(the.treat="treat_bdf")
ext_fn(the.treat="treat_abcd")
ext_fn(the.treat="treat_ab")

mean(wrkdat$subscribed)




extreme_cmh_fn<-function(the.treat="treatmentF",the.group="A"){
	df<-data_fn2(x=the.treat,group=the.group)
	f <- reformulate(paste(the.treat,"|batchday2F"),response="subscribed_bnd")
	# CMH Test, use asymptotic results for now for now
	cmh<-cmh_test(f,data=df)
	return(cmh)


}


ext_cmh_gen_A<-extreme_cmh_fn(the.group="A")
ext_cmh_gen_B<-extreme_cmh_fn(the.group="B")
ext_cmh_gen_C<-extreme_cmh_fn(the.group="C")
ext_cmh_gen_D<-extreme_cmh_fn(the.group="D")
ext_cmh_gen_E<-extreme_cmh_fn(the.group="E")
ext_cmh_gen_F<-extreme_cmh_fn(the.group="F")

# All of the general tests remain significant
# ACE vs BDF #
ext_cmh_bdf_A<-extreme_cmh_fn(the.treat="treat_bdf",the.group="A")
ext_cmh_bdf_B<-extreme_cmh_fn(the.treat="treat_bdf",the.group="B")
ext_cmh_bdf_C<-extreme_cmh_fn(the.treat="treat_bdf",the.group="C")
ext_cmh_bdf_D<-extreme_cmh_fn(the.treat="treat_bdf",the.group="D")
ext_cmh_bdf_E<-extreme_cmh_fn(the.treat="treat_bdf",the.group="E")
ext_cmh_bdf_F<-extreme_cmh_fn(the.treat="treat_bdf",the.group="F")

# Benefits (ABCD) vs No Benefits (EF)
ext_cmh_abcd_A<-extreme_cmh_fn(the.treat="treat_abcd",the.group="A")
ext_cmh_abcd_B<-extreme_cmh_fn(the.treat="treat_abcd",the.group="B")
ext_cmh_abcd_C<-extreme_cmh_fn(the.treat="treat_abcd",the.group="C")
ext_cmh_abcd_D<-extreme_cmh_fn(the.treat="treat_abcd",the.group="D")
ext_cmh_abcd_E<-extreme_cmh_fn(the.treat="treat_abcd",the.group="E")
ext_cmh_abcd_F<-extreme_cmh_fn(the.treat="treat_abcd",the.group="F")

# List (AB) vs Quiz (CD)
ext_cmh_ab_A<-extreme_cmh_fn(the.treat="treat_ab",the.group="A")
ext_cmh_ab_B<-extreme_cmh_fn(the.treat="treat_ab",the.group="B")
ext_cmh_ab_C<-extreme_cmh_fn(the.treat="treat_ab",the.group="C")
ext_cmh_ab_D<-extreme_cmh_fn(the.treat="treat_ab",the.group="D")
ext_cmh_ab_E<-extreme_cmh_fn(the.treat="treat_ab",the.group="E")
ext_cmh_ab_F<-extreme_cmh_fn(the.treat="treat_ab",the.group="F")
```

# Code Appendix

```{r appendix, eval=F,echo=T}
<<setup>>
<<dv>>
<<cmh>>
<<fig1>>
<<TukeyHSD>>
<<figTukey>>
<<subgroup>>
<<tabbdf>>
<<tababcd>>
<<tabab>>
<<unmatch>>
<<sensitivity>>
<<examp>>
<<cmhSim>>
<<figCMHsim>>
<<tukeySim>>
<<tukeytab>>
<<figTukeypval>>
<<figTukeycoef>>
<<ext>>
```

